# More challenging example: Ebola in the Democratic Republic of Congo

The rates of transition between states in this model is given by:

\begin{align*}
    P\left[\mbox{infection event in}~[t, t + \delta t)\right] = \beta S I / N + o(\delta t)\\
    P\left[\mbox{infectivity event in}~[t, t + \delta t)\right] = \delta E + o(\delta t)\\
    P\left[\mbox{removal event in}~[t, t + \delta t)\right] = \gamma I + o(\delta t)
\end{align*}

where $\beta$ is *time-dependent*, such that:

$$
    \beta = \left\{
    \begin{align}
        &\beta & \mathrm{if}~t < t_{int},\\
        &\beta e^{-q(t - t_{int})} & \mathrm{if}~t \geq t_{int},
    \end{align}\right.
$$

where $t_{int}$ is the time at which intervention strategies were introduced. The challenge here is that in a stochastic system we require that the event rates are piecewise constant, and thus the continuous exponential decay is hard to capture. Instead we can approximate this by assuming that the rate only decays at the beginning of each day. Hence the transmission term becomes:

$$
    \beta = \left\{
    \begin{align}
        &\beta & \mathrm{if}~t < t_{int},\\
        &\beta e^{-q(\lfloor t \rfloor - t_{int})} & \mathrm{if}~t \geq t_{int},
    \end{align}\right.
$$
where $\lfloor t \rfloor$ corresponds to rounding $t$ down to the nearest integer. Here $t_{int} = 126$, meaning that control interventions were introduced on day 126 of the outbreak. Hence the transmission rate between day 126 and 127 is:
$$
    \beta e^{-q(126 - 126)} = \beta,
$$
the transmission rate between day 127 and 128 is:
$$
    \beta e^{-q(127 - 126)} = \beta e^{-q},
$$
and so on. This behaviour can be captured in C by using the `floor()` function (which rounds down to the nearest integer). We also need to update our rate at each daily time-step. We can do this by passing a `afterTstar` argument to the `mparseRcpp()` function. This inserts a small piece of C code after each new event time has been simulated. In this case we wish to update the `beta` rate at each time point, therefore:

```{r}
## define a conditional statement to update the rates
afterTstar <- "if(tstar > 126.0 && tstar < tstop) {
    if(t < 126.0) {
        t = 126.0;
    }
    while(tstar > floor(t + 1.0) && tstar < tstop){
        t = floor(t + 1.0);
        rates[0] = pars[0] * exp(-pars[3] * (t - 126.0)) * u[0] * u[1] / sum(u);
        totrate = sum(rates);
        tstar = t + R::rexp(1.0 / totrate);
    }
}"

```

```{r}
## set up model
transitions <- c(
    "S -> beta * S * I / (S + E + I + R) -> E", 
    "E -> delta * E -> I", 
    "I -> gamma * I -> R"
)
compartments <- c("S", "E", "I", "R")
pars <- c("beta", "delta", "gamma", "q")
model <- mparseRcpp(
    transitions = transitions, 
    compartments = compartments,
    pars = pars,
    afterTstar = afterTstar
)
```

```{r}
model <- compileRcpp(model)
model
```

Now we can set priors and initial states:

```{r}
## set priors
priors <- data.frame(
    parnames = c("beta", "delta", "gamma", "q"), 
    dist = rep("gamma", 4), 
    stringsAsFactors = F
)
priors$p1 <- rep(2, 4)
priors$p2 <- c(10, 10, 1 / 0.07, 10)

## set initial states
iniStates <- data.frame(S = 5364499, E = 0, I = 1, R = 0)
```

Now we set up the data to match to (final epidemic size and date of final removal):

```{r}
## define the targeted summary statistics
data <- data.frame(finalsize = 316, finaltime = 191)
```

Finally we set the number of particles and a sequence of tolerances:

```{r}
## set number of particles required
npart <- 200

## set tolerances
tols <- matrix(rep(round(seq(300, 40, length.out = 10)), each = 2), ncol = 2, byrow = T)
tols <- as.data.frame(tols)
colnames(tols) <- c("finalsize", "finaltime")
```

We then set up a function to run the model, extract the final epidemic size and date of the final removal, and return the relevant measures:

```{r}
## function to match simulations
simEbola <- function(pars, data, tols, u, model) {
    ## run model
    sims <- model(pars, 0, data[2] + tols[2], u)
    
    ## this returns a vector of the form:
    ## completed (1/0), t, S, E, I, R (here)
    if(sims[1] == 0) {
        ## if simulation rejected
        return(NA)
    } else {
        ## extract finaltime and finalsize
        finaltime <- sims[2]
        finalsize <- sims[6]
    }
    
    ## return vector if match, else return NA
    if(all(abs(c(finalsize, finaltime) - data) <= tols)){
        return(c(finalsize, finaltime))
    } else {
        return(NA)
    }
}
```

Now we run the ABC-SMC algorithm:

```{r}
## run ABC-SMC algorithm
post <- ABCSMC(data, priors, simEbola, iniStates, npart, tols, parallel = T, model = model)
```

```{r}
## function to calculate R0 and length of
## epidemiological periods
R0fn <- function(beta, delta, gamma) {
    data.frame(R0 = beta / gamma, latperiod = 1 / delta, infperiod = 1 / gamma)
}

## summarise approximate posterior
summary(post, transfunc = R0fn)
```

```{r, fig.width = 8, fig.height = 8}
## plot approximate posteriors
plot(post, transfunc = R0fn, gen = c(1, 5, 10))
```

```{r}
## plot accepted outputs
plot(post, "output", gen = c(1, 5, 10))
```

This ran relatively quickly, so now run for another few generations...

```{r}
tols <- matrix(rep(seq(30, 10, by = -10), each = 2), ncol = 2, byrow = T)
tols <- as.data.frame(tols)
colnames(tols) <- c("finalsize", "finaltime")

## run ABC-SMC algorithm
post <- ABCSMC(post, tols, parallel = T)
```

Now summarise the outputs:

```{r, fig.width = 10, fig.height = 5}
## summarise approximate posterior
summary(post, transfunc = R0fn)
```

```{r, fig.width = 8, fig.height = 8}
## plot approximate posteriors
plot(post, transfunc = R0fn, gen = c(1, 5, 13))
```

```{r}
## plot accepted outputs
plot(post, "output", gen = c(1, 5, 13))
```

<!-- ## Speeding up simulations using stopping criteria -->

<!-- One way to speed up the algorithms is to note that if we have summary statistics that are **monotonically** increasing, then we can monitor these criteria during the simulation and reject the simulation as soon as the simulated summary measure is greater than the observed summary measure by more than the tolerance. This means that we do not have to run the simulation to completion to reject it. -->

<!-- We've already done this to a certain extent by only simulating up to time $T + \mbox{tol}$, where $T$ is the final removal time. The rationale was the same; if the epidemic is still ongoing at time $T + \mbox{tol}$, then by definition the difference between the simulated final removal time and the observed final removal time will be greater than the tolerance, and furthermore this distance will keep increasing. Hence we do not have to find out the exact final removal time in order to reject the simulation. -->

<!-- Here we will use a `stopCrit` argument to `mparseRcpp()` to define additional stopping criteria, based on the other summary statistics. The argument is defined as a **conditional statement** that defines when to reject. For example, to add a stopping criterion based on the final epidemic size, we can reject once $C^* > C_F + \mbox{tol}$, where $C^*$ is the **simulated** number of convalescences and $C_F$ is the final **observed** number of convalescences. Hence, -->

<!-- ```{r} -->
<!-- model <- mparseRcpp( -->
<!--     transitions = transitions,  -->
<!--     compartments = compartments, -->
<!--     pars = pars, -->
<!--     tspan = T, -->
<!--     addVars = c("CF", "tolF"), -->
<!--     stopCrit = "u[3] > (CF + tolF)" -->
<!-- ) -->
<!-- model <- compileRcpp(model) -->
<!-- model -->
<!-- ``` -->

<!-- ```{r} -->
<!-- ## set up function to perform simulation and check matching -->
<!-- simBS <- function(pars, data, tols, u, model, tspan, B, CF) { -->

<!--     ## run model -->
<!--     sims <- model(pars, 0, data[2] + tols[2], u, tspan, CF, tols[1]) -->

<!--     ## this returns a matrix with columns of the form: -->
<!--     ## completed (1/0), t, S, I, B, C (here) -->
<!--     ## the final row is the summary of the epidemic -->
<!--     ## at the final time point (as if tspan had not  -->
<!--     ## been used) -->
<!--     ## -->
<!--     ## the earlier rows correspond to states of the  -->
<!--     ## system at each time point t (the 'completed' -->
<!--     ## column is extraneous here, and so is set to NA) -->
<!--     ## -->
<!--     ## Firstly, separate the time-series counts from the -->
<!--     ## final epidemic summaries -->
<!--     simSum <- sims[nrow(sims), ] -->
<!--     counts <- sims[-nrow(sims), -1] -->
<!--     if(simSum[1] == 0) { -->
<!--         ## if simulation rejected -->
<!--         return(NA) -->
<!--     } else { -->
<!--         ## extract finaltime and finalsize -->
<!--         finaltime <- simSum[2] -->
<!--         finalsize <- simSum[6] -->

<!--         ## calculate sum-of-squared distances of -->
<!--         ## simulations from observations -->
<!--         SB <- sum((B - counts[, 2])^2) -->
<!--     } -->

<!--     ## return vector if match, else return NA -->
<!--     if(all(abs(c(finalsize, finaltime, SB) - data) <= tols)){ -->
<!--         return(c(finalsize, finaltime, SB)) -->
<!--     } else { -->
<!--         return(NA) -->
<!--     } -->
<!-- } -->
<!-- ``` -->

<!-- ```{r, fig.width = 8, fig.height = 4} -->
<!-- ## run ABC-SMC algorithm -->
<!-- post <- ABCSMC(sumStat, priors, simBS, iniStates, npart,  -->
<!--                tols, parallel = T,  -->
<!--                model = model, tspan = BS$day, B = BS$B, CF = finalsize) -->

<!-- ## plot approximate posteriors and simulated -->
<!-- ## summary statistics -->
<!-- plot(post) -->
<!-- plot(post, "output") -->
<!-- ``` -->
