# Particle MCMC

Here we will return to our influenza in a boarding school example. Firstly, load the data and the `SimBIID` package:

```{r, warning = F, message = F}
## load data
BS <- read.csv("BS.csv", header = T)

## load library
library(SimBIID)
```

Here we will run a PMCMC routine [@andrieuetal:2010] using a bootstrap particle filter to estimate the likelihood [@gordonetal:1993]. Note that PMCMC is extremely computationally intensive, and the only real way to make it tractable for many problems is to code both the simulation code and the MCMC code in a low-level language such as C. The `SimBIID` package provides a function `PMCMC()` that runs this algorithm, and if you pass a `SimBIID_model` object to this function, it will automatically compile in the correct manner.

The other thing is that we will be matching at a set of given time points, so we cannot add a `tspan` argument. Rather, this will be determined by the `data` that we pass to `PMCMC()`. In addition, we need to specify an observation process. This is passed as an argument called `obsProcess` to the `mparseRcpp()` function. This argument must be a `data.frame`, with columns in the order: `dataNames`, `dist`, `p1`, `p2`. 

* `dataNames` is a character denoting the relevant compartment name to place the observation process onto; 
* `dist` is a character specifying the distribution of the observation process (must be one of `"unif"`, `"pois"` or `"binom"` at the current time); 
* `p1` is the first parameter (the lower bound in the case of `"unif"`, the rate in the case of `"pois"`, or the size in the case of `"binom"`); 
* `p2` is the second parameter (the upper bound in the case of `"unif"`, `NA` in the case of `"pois"`, and `prob` in the case of `"binom"`).

Here we will place a Poisson observation process around the $B$ curve, such that:
$$
    B^o_t \sim Po(\rho B^s_t),
$$
where $B^o_t$ is the **observed** $B$ count at time $t$, $B^s_t$ is the simulated count, and $\rho$ is some value in $(0, 1]$ corresponding to the **reporting rate**. 

The `data` we will pass to the `PMCMC()` function will be a `data.frame` with the first column corresponding to `time` and the second corresponding to the *observed* $B$ curve. hence,

```{r}
## set up data to pass to PMCMC
BS_dat <- data.frame(time = BS$day, Bo = BS$B)
head(BS_dat)
```
To set up the observation process, we define a `data.frame` as follows:

```{r}
## set up observation process
obs <- data.frame(
    dataNames = "Bo",
    dist = "pois",
    p1 = "rho * B + 1e-5",
    p2 = NA,
    stringsAsFactors = F
)
```

Here we note that we need to include the `rho` parameter into our model definition. Hence for completeness:

```{r}
## set up model
transitions <- c(
    "S -> beta * S * I / (S + I + B + C) -> I", 
    "I -> muI * I -> B", 
    "B -> muB * B -> C")
compartments <- c("S", "I", "B", "C")
pars <- c("beta", "muI", "muB", "rho")
model <- mparseRcpp(
    transitions = transitions, 
    compartments = compartments,
    pars = pars,
    obsProcess = obs
)
```

> **Note:** we do **not** have to compile the model here. The `PMCMC()` function will do this for us. This is because we need to compile as an object to run from C rather than R, so the `PMCMC()` function deals with this.

Now we run the PMCMC algorithm for 5,000 iterations, using 50 particles. We pass the same initial states and priors as in the ABC-SMC practical, but with an additional prior for $\rho \sim U(0, 1)$ (since $\rho \in (0, 1)$).

```{r}
## set priors
priors <- data.frame(parnames = c("beta", "muI", "muB", "rho"), 
                     dist = rep("unif", 4), 
                     stringsAsFactors = F)
priors$p1 <- c(0, 0, 0, 0)
priors$p2 <- c(5, 5, 1, 1)
priors

## define initial states
iniStates <- c(S = 762, I = 1, B = 0, C = 0)

## set initial parameter values (informed by ABC-SMC runs)
iniPars <- c(beta = 3.5, muI = 2.2, muB = 0.71, rho = 0.99)

## run PMCMC algorithm
post <- PMCMC(BS_dat, priors, model, iniStates, iniPars = iniPars,
                 npart = 50, niter = 5000, nprintsum = 1000)
```

```{r}
## plot MCMC traces
plot(post, "trace")
```

We can see that the chain looks like it's converging towards a stationary distribution, but let's run it for a bit longer. We can do this simply by passing our current `PMCMC` object back into the `PMCMC()` function:

```{r}
post <- PMCMC(post, niter = 5000, nprintsum = 1000)
plot(post, "trace")
```

## Optimising the number of particles

The mixing of the chain and the speed of convergence is related to the number of particles (amongst other things). There is no strong consensus, but a rule-of-thumb is to try to choose the number of particles such that the variance of the log-likelihood estimate at a suitable set of parameters $\theta^\prime$ is between 1--3. Clearly the larger the number of particles, the higher the computational burden, so in practice the additional computational burden of the simulations must be balanced against the improved mixing and faster convergence. This is tricky, so instead here we take a simpler approach.

Firstly we run the chain for a fixed number of particles until it looks like the chain has converged. Then we choose a set of parameter values $\theta^\prime$ chosen to be the posterior medians. We then generate 500 estimates of the log-likelihood for a range of different numbers of particles, from which we can calculate the variance of these estimates. We then choose the smallest number of particles with a variance of the log-likelihood of less than 3.

Hence, from the training runs above we can extract the posterior medians:

```{r}
postMed <- window(post, start = 2000)
postMed <- as.matrix(postMed$pars)
postMed <- apply(postMed, 2, median)
postMed <- postMed[-length(postMed)]
postMed
```

We can produce 500 estimates of the log-likelihood by setting the `fixpars = T` argument to the `PMCMC()` function, passing in the `postMed` estimates above.

```{r}
BS_train <- PMCMC(BS_dat, priors, model, iniStates, iniPars = postMed,
                 npart = 25, niter = 500, fixpars = T)
```

This produces a list where the first element is a matrix of log-likelihood estimates. Hence we can extract this and calculate the sample variance as follows:

```{r}
## calculate the sample variance
BS_train <- var(BS_train$output)
BS_train
```

Here the variance is `r BS_train`, which is much larger than 3. Hence let's try increasing the number of particles and repeating these steps.

```{r, results = "hide"}
## generate numbers of particles to trial
npart <- c(50, 75, 100, 125, 150)

BS_train <- list()
for(i in 1:length(npart)){
    BS_train[[i]] <- PMCMC(BS_dat, priors, model, iniStates, iniPars = postMed,
                 npart = npart[i], niter = 500, fixpars = T)
    BS_train[[i]] <- var(BS_train[[i]]$output)
}
names(BS_train) <- paste0("npart = ", npart)
BS_train <- do.call("c", BS_train)
```

```{r}
BS_train
```

Here we will choose the number of particles to be 100.

## Visualising and summarising the posterior distributions

We now start a new chain using 100 particles, and with starting values derived from the training runs.

```{r}
post <- PMCMC(BS_dat, priors, model, iniStates, iniPars = postMed,
                 npart = 100, niter = 10000, nprintsum = 1000)
```

We can visualise the MCMC chain and the approximate posterior distributions (after removing some burn-in):

```{r}
## plot and summarise MCMC output
plot(post, "trace")

## remove burn-in
post <- window(post, start = 2000)

## plot and summarise outputs
plot(post)
summary(post)
```

```{task}
Produce summaries of the posteriors for $R_0$ and the average length of the infectious period. **Hint**: use a `transfunc` argument as before.
```

```{solution}

``{r, boot-soltrans}
## function to calculate R0 and length of
## infectious periods
R0fn <- function(beta, muI) {
    data.frame(
        R0 = beta / muI, 
        infperiod = 1 / muI
    )
}

## summarise approximate posterior
summary(post, transfunc = R0fn)
``

```




