# Approximate Bayesian Computation

Here we will run the ABC-SMC routine of Toni et al. (2009).

```{r, abc-sums, include = F}
## extract summaries
finaltime <- max(BS$day)
finalsize <- 512
```

## Summary statistics

In order to run an ABC routine, it is necessary to define a set of lower order summary statistics to match to. The data here are time-series counts of ***bed-rest *** and ***convalescence*** events. A very simple option would be to match to:

* final epidemic size (i.e. total number of removals across the time course of the epidemic), and
* time of final removal (in this case when the epidemic process ceased).

Although simple, these two measures serve to give us some information on both the **length** and **magnitude** of the epidemic, and should contain at least some useful information about the parameters. In this case the final removal time is `r finaltime` days and the final epidemic size is `r finalsize` individuals.

## Simulation model

In order to use the any ABC routine, we require a simulation model. Here we will use the approach described in the previous section, and specify a model using the `mparseRcpp()` function. The ABC-SMC routine is coded in a function called `ABCSMC()`. If you look at the help file for the `ABCSMC()` function (e.g. `?ABCSMC`), you will see that the first argument to the function must be either an `ABCSMC` object (we will come to this later), or a named `vector` with entries containing the observed summary statistics to match to. Let's create this data object:

```{r, abc-sums1}
## create vector of summary statistics
sumStat <- c(finalsize = 512, finaltime = max(BS$day))
sumStat
```

The second argument must be a `data.frame` containing information about the prior distributions for the parameters. Here we will let $\beta \sim U(0, 5)$, $\mu_I \sim U(0, 5)$ and $\mu_B \sim U(0, 1)$. We can specify this as follows:

```{r, abc-priors}
## set priors
priors <- data.frame(parnames = c("beta", "muI", "muB"), 
                     dist = rep("unif", 3), stringsAsFactors = F)
priors$p1 <- c(0, 0, 0)
priors$p2 <- c(5, 5, 1)
priors
```

Here the first column corresponds to the names of the parameters, the second to the type of prior distribution (`"unif"`, `"gamma"` or `"norm"`), and the final two columns to the hyperparameters (upper and lower limits for `"unif"`; shape and scale for `"gamma"`; or mean and standard deviation for `"norm"`).

The third argument is a function that runs the simulator and checks whether the simulation matches the data. The first four arguments to this function must be `pars`, `data`, `tols` and `u` (but you can pass more arguments in if required---see below). Within the function:

* `pars`: is a *vector* of parameters (the order must match the order of the `priors` argument to the `ABCSMC` function);
* `data`: a *vector* of data points to match to (must match the order of the `x` argument to the `ABCSMC` function);
* `tols`: a *vector* of tolerances (must match the order of `data`);
* `u`: a *vector* of initial states (must match order of the `u` argument to the `ABCSMC` function).

> **Please note: there is no internal check on you getting these orders correct. It is up to you to be careful when setting up this function**.

If the simulations do not match the data then the function must return an `NA`, else it must returns a vector of simulated summary measures. In this latter case the output from the function must be a vector with length equal to `length(data)` and with entries in the same order as `data`. It is possible to add further arguments to this function, as long as they appear after `pars`, `data`, `tols` and `u`. For example, in our case we are going to pass our simulation model in as an additional argument called `model` e.g.

```{r, abc-func}
## set up function to perform simulation and check matching
simBS <- function(pars, data, tols, u, model) {
    
    ## run model
    sims <- model(pars, 0, data[2] + tols[2], u)
    
    ## 'sims' is a vector of outputs of the form:
    ## completed (1/0), t, S, I, B, C (here)
    if(sims[1] == 0) {
        ## if epidemic still going at 
        ## time = finaltime + tol, then reject
        return(NA)
    } else {
        ## extract finaltime and finalsize
        finaltime <- sims[2]
        finalsize <- sims[6]
    }
    
    ## return vector if match, else return NA
    if(all(abs(c(finalsize, finaltime) - data) <= tols)){
        return(c(finalsize, finaltime))
    } else {
        return(NA)
    }
}
```

> **Note**: To speed things up here we will not use the `run()` function, rather we will create the model using `mparseRcpp()`, and then compile it using `compileRcpp()`, before passing the compiled model to the `ABCSMC()` function. The `run()` function does all this internally, but here we will do it in two stages. 

Hence, to specify and compile the model we can run:

```{r, abc-model}
model <- mparseRcpp(
    transitions = transitions, 
    compartments = compartments,
    pars = pars
)
```

```{r, abc-compmod}
model <- compileRcpp(model)
model
```

You can see that the compiled model is an R `function` that takes four arguments, `pars`, `tstart`, `tstop` and `u`. Convenient eh?

> **Note**: You can also use you own simulation code in this function, as long as you adhere to these rules, you do not have to use `mparseRcpp()` (you could use `SimInf` here for example).

The `simBS` function we have made therefore returns an `NA` if the simulations do not match the summary statistics, or a vector of simulated summary statistics if it does. Next we need to specify the initial states of the system (as a named `vector`---which we already have as an object called `iniStates`).

We can then either specify a `matrix` of tolerances to match to (these must be decreasing over each generation of the ABC-SMC algorithm), or alternatively specify the proportion of simulated outcomes at each generation to use to derive adaptive tolerances (e.g. if `ptols = 0.5`, then we choose tolerances at the $t^{\mbox{\scriptsize th}}$ generation such that we would have accepted 50% of the simulations at the $(t - 1)^{\mbox{\scriptsize th}}$ generation. Note that if we wish to use this latter approach, then we will need to give the algorithm some initial tolerances for generation 1.

> **Note**: the names and order of the tolerances must match the `x` argument.

```{r, abc-tols}
## set tolerances
tols <- c(finalsize = 50, finaltime = 50)
```

Now let's run the routine for `ngen = 4` generations of ABC, with `ptols = 0.5` using 50 particles. Notice that we can pass the additional arguments that `simBS()` needs (`model` in this case) as additional arguments passed to `ABCSMC()`:

```{r, abc-abc}
## run ABC-SMC algorithm
post <- ABCSMC(
    x = sumStat, 
    priors = priors, 
    func = simBS, 
    u = iniStates, 
    npart = 50,
    tols = tols, 
    ptol = 0.5,
    ngen = 4,
    model = model
)
```

 > **Note**: these algorithms are computationally intensive, so if you can spare the processing power, it's often good to set `parallel = T` to use parallel processing. However, depending on the model and your architecture, it's not always faster, so you might need to use your judgement. Windows users commiserate: your architecture doesn't support the `mclapply()` function, from the `parallel` package, so you'll always have to run in serial I'm afraid...

We can plot the approximate posterior distributions over the generations as follows:

```{r, abc-plot, fig.width = 8, fig.height = 4}
## plot approximate posteriors
plot(post)
```

We can plot the simulated summary statistics from the accepted particles at each generation as:

```{r, abc-plot1, fig.width = 8, fig.height = 4}
plot(post, type = "output")
```

Given the speed of the simulations, let's try running for a few more generations. We can pass the current `ABCSMC` object (`post` here) back into the `ABCSMC()` function and run for a few more generations:

```{r, abc-abc1, fig.width = 8, fig.height = 4}
## run for a few more generations
post <- ABCSMC(x = post, ptols = 0.5, ngen = 3, parallel = T)
```

```{r, abc-plot2}
## plot approximate posteriors and simulated
## summary statistics
plot(post)
plot(post, "output")
```

Notice how the approximate posteriors are tightening up as we require to match more precisely. Notice also that the acceptance rate of each generation of ABC-SMC drops as the tolerances decrease. In fact we can see this more clearly if we plot just the first and final generation. Fortunately, we can choose which generations to plot using the `gen` argument to `plot()` e.g.

```{r, abc-plot3, fig.width = 8, fig.height = 4}
## plot approximate posteriors
plot(post, gen = c(1, 7))

## plot accepted outputs
plot(post, "output", gen = c(1, 7))
```

We can also produce joint density plots (if the `GGally` package is installed):

```{r, abc-plot4, fig.width = 6, fig.height = 6}
## joint distributions
plot(post, gen = c(1, 7), joint = T)
```

A call to `summary()` produces weighted estimates for the posterior means and standard deviations for the parameters in the final generation:

```{r, abc-sum}
summary(post)
```

## Calculate posterior for $R_0$

We might also want to calculate posterior distributions for transformations of the parameters. This can be done by specifying a `transfunc` argument to the `summary()` method (this function must return a `data.frame` object). For example, as discussed in the lecture, if we have $\beta$ and $\mu_I$, then we can also calculate the marginal posterior distribution for $R_0$ (here defined as $R_0 = \frac{\beta}{\mu_I}$), as well as, let's say, the length of the infectious period. Hence:

```{r, abc-R0}
## function to calculate R0 and infectious period
R0fn <- function(beta, muI) {
    data.frame(R0 = beta / muI, infperiod = 1 / muI)
}
summary(post, transfunc = R0fn)
```

We can plot distributions for transformed variables in a similar way:

```{r, abc-plot5, fig.width = 8, fig.height = 4}
## plot distribution for R0
plot(post, transfunc = R0fn, gen = c(1, 7))
```

Note that we can also ask various probabilistic questions of these distributions, since we are using a Bayesian framework. For example, what is the probability that $R_0$ is greater than one? A Monte Carlo estimate of this can be produced simply by counting the proportion of the posterior samples for $R_0$ that lie above one. (**Note**: this would be slightly *biased*, since we actually have unequal weights for these samples. However, we can use our transformation function above to generate an estimate as below.)

```{r, abc-R01}
## function to calculate whether R0 > 1
R0gt <- function(beta, muI) {
    data.frame(R0gt = as.numeric((beta / muI) > 1))
}
summary(post, transfunc = R0gt)
```

## Adding additional matching criteria

Matching to final epidemic size and the date of the final removal only is quite crude. We could also incorporate information regarding the observed $B$ and $C$ curves. One option would be to generate some summary measure of distance between the simulated and observed curves, something like a sum-of-squared differences e.g.
$$
    S_B = \sum_{t = 1}^T \left(B_t - B^*_t\right)^2,
$$
where $B_t$ is the **observed** counts at time $t$, and $B^*_t$ are the corresponding **simulated** counts at time $t$, and $T$ is the total number of time points. Therefore if the simulated time-series matches the data *exactly*, then $S_B = 0$, with large values of $S_B$ corresponding to poor matches between the simulated and observed counts.

To calculate $S_B$, we have to re-compile the model with the `tspan` option turned on.

```{r, abc-model2}
model <- mparseRcpp(
    transitions = transitions, 
    compartments = compartments,
    pars = pars,
    tspan = T
)
model <- compileRcpp(model)
model
```

You can now see that the new function has an additional `tspan` argument, which corresponds to a vector of times that we wish to return the states of the system. We therefore also have to pass a `tspan` argument to our `simBS` function. In addition, we will also need to pass the observed time-series counts to this function (which we call `B` here).

```{r, abc-func2}
## set up function to perform simulation and check matching
simBS <- function(pars, data, tols, u, model, tspan, B) {
    
    ## run model
    sims <- model(pars, 0, data[2] + tols[2], u, tspan)
    
    ## 'sims' is now a list, with the first element a vector
    ## of the form: completed (1/0), t, S, I, B, C (here),
    ## and the second element is a matrix containing the 
    ## time-series counts
    simSum <- sims[[1]]
    counts <- sims[[2]]
    if(simSum[1] == 0) {
        ## if epidemic still going at 
        ## time = finaltime + tol, then reject
        return(NA)
    } else {
        ## extract finaltime and finalsize
        finaltime <- simSum[2]
        finalsize <- simSum[6]
        
        ## calculate sum-of-squared distances of
        ## simulations from observations
        SB <- sum((B - counts[, 4])^2)
    }
    
    ## return vector if match, else return NA
    if(all(abs(c(finalsize, finaltime, SB) - data) <= tols)){
        return(c(finalsize, finaltime, SB))
    } else {
        return(NA)
    }
}
```

To create some initial tolerances, let's append an initial value for `SB` to our original `tols` object:

```{r, abc-tols2, fig.width = 8, fig.height = 4}
## set up new set of tolerances
tols <- c(tols, SB = 1e6)

## set up data to match to
sumStat <- c(sumStat, SB = 0)
```

Now we can run our routine again (notice the final row below contains the additional arguments we now need for `simBS()`):

```{r, abc-abc3}
## run ABC-SMC algorithm
post <- ABCSMC(
    x = sumStat, 
    priors = priors, 
    func = simBS, 
    u = iniStates, 
    npart = 50,
    tols = tols,
    ptols = 0.5,
    ngen = 3, 
    parallel = T, 
    model = model, tspan = BS$day, B = BS$B
)
```

```{r, abc-plot6}
## plot approximate posteriors and simulated
## summary statistics
plot(post)
plot(post, "output")
```

```{task}
Add another summary measure corresponding to the sum-of-squared distances between the observed and simulated $C$ curves. Re-run your ABC-SMC routine. 
```

```{solution}

``{r, abc-solfunc}
## set up function to perform simulation and check matching
simBS <- function(pars, data, tols, u, model, tspan, B, C) {
    
    ## run model
    sims <- model(pars, 0, data[2] + tols[2], u, tspan)
    
    ## 'sims' is now a list, with the first element a vector
    ## of the form: completed (1/0), t, S, I, B, C (here),
    ## and the second element is a matrix containing the 
    ## time-series counts
    simSum <- sims[[1]]
    counts <- sims[[2]]
    if(simSum[1] == 0) {
        ## if epidemic still going at 
        ## time = finaltime + tol, then reject
        return(NA)
    } else {
        ## extract finaltime and finalsize
        finaltime <- simSum[2]
        finalsize <- simSum[6]
        
        ## calculate sum-of-squared distances of
        ## simulations from observations
        SB <- sum((B - counts[, 4])^2)
        SC <- sum((C - counts[, 5])^2)
    }
    
    ## return vector if match, else return NA
    if(all(abs(c(finalsize, finaltime, SB, SC) - data) <= tols)){
        return(c(finalsize, finaltime, SB, SC))
    } else {
        return(NA)
    }
}
``

To create a sequence of tolerances:

``{r, abc-soltol}
## set initial tolerances
tols <- c(tols, SC = 1e6)
``

Finally set up the data to match to and run the model:

``{r, abc-solabc}
## set up data to match to
sumStat <- c(sumStat, SC = 0)

## run ABC-SMC algorithm
post <- ABCSMC(
    x = sumStat, 
    priors = priors, 
    func = simBS, 
    u = iniStates, 
    npart = 50,
    tols = tols,
    ptols = 0.5,
    ngen = 4,
    parallel = T, 
    model = model, tspan = BS$day, B = BS$B, C = BS$C
)
``

```
